
high-level todos:
 - complete basic training of single timestep model today
    - test the framework on it
 - complete dreamer and world-models model learning today
    - shape the apis based on dreamer
    - other models should be similar






todos:
 - 
 - 






future todos:
 - compare parameters in dreamer and world-models.. should be roughly the same
 - how to do hyperparameter search.. tune?
 - should you change the sampling procedure to same as supervised learning:
    - sample from shuffled data IDs
    - training loop can probably done in terms of epochs, as dataset is finite






NOTES:
when to stop the simulation:
 - when you added required number of steps inside buffer (or disk)

for logging, is log_every = 1000 log every 1000 steps:
 - yes, every 1000 steps, we log. 
 - steps are based on num_envs and action_repeat

how is self._step updated inside the __call__ method.
 - self._step += num_envs * action_repeat
    - if num_envs = 1, action_repeat = 2, 2 steps have been added.
    - self._step works in the same way as count_steps -> steps in the main method
 - __call__ is called for each new transition added. each transition is worth action_repeat steps
 - self._step also accounts for those transitions are being generated, but have not yet been saved
    - this is why for ending training on those that are on disk are considered

who is counting the steps, if the graphs being generated are based on no. of steps:
 - counted inside of __call__ method in the form of self._step
 - also inside the main method, count_steps is used to count the steps in buffer (or disk)

does dreamer load episodes into memory or just load them from the disk:
 - dreamer loads the episodes to cache, and a generator fetches randomly from cache






create a training loop
 - given any model, get samples and 'update' dummy model

 - replicate dreamer training loop
 - copy relevant dreamer files
 - copy tf first
 - later on dreamer-pytorch can be added




checkpointing and loading of trained models
 - prefer the qmix style of repeated saving
 - but if short of time, can do danijar way: saved last model




- fix preprocessing






DONE:
 - running sowcode3 to record compact dtse episodes
 - debugged the load_episodes method, to get samples the danijar way






FURTHER NOTES:

dreamer episode:
>>> episode.keys()
dict_keys(['image', 'action', 'reward', 'discount'])
>>> episode['image'].shape
(501, 64, 64, 3)
>>> episode['action'].shape
(501, 18)
>>> episode['reward'].shape
(501,)
>>> episode['discount'].shape
(501,)

prec.global_policy().compute_dtype
'float32'

sow45_code3 episode:
{k: v.dtype for k, v in episode.items()}
{'action': dtype('int64'), 'image': dtype('float64'), 'reward': dtype('int64')}